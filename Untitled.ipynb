{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.txt', sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the good data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define X and Y arrays\n",
    "X = data.iloc[:,:data.shape[1]-1].as_matrix()\n",
    "Y = data.iloc[:,data.shape[1]-1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We center the Y\n",
    "Y_tilde = Y - Y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "beta = np.random.uniform(size = X.shape[1])\n",
    "sigma_sq = np.random.uniform()\n",
    "tau_sq = np.random.uniform(size = X.shape[1])\n",
    "\n",
    "beta_ = []\n",
    "sigma_sq_ = []\n",
    "tau_sq_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D_tau = np.diag(tau_sq)\n",
    "A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "multi_norm_cov = sigma_sq * np.linalg.inv(A)\n",
    "beta_.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (X.shape[0]-1+X.shape[1])/2\n",
    "scale = ((Y_tilde - X.dot(beta)).dot((Y_tilde - X.dot(beta))) + beta.transpose().dot(np.linalg.inv(D_tau)).dot(beta))/2\n",
    "sigma_sq_.append(sc.invgamma.rvs(a = shape, scale = scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\tau^2_1, ..., \\tau^2_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Say lambda 0 is equal to 1\n",
    "lambda_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.sqrt(lambda_**2*sigma_sq/beta**2)\n",
    "scale = lambda_**2\n",
    "tau_sq_.append(np.random.wald(mean, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(tau_sq)):\n",
    "    t.append(np.random.wald(mean[i], scale))\n",
    "tau_sq_.append(np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler(n, lambda_):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_**2*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_**2, X.shape[1])\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "    return tau_sq[int(n/2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "For the Bayesian Lasso, each iteration of the algorithm involves running the Gibbs sampler using a $\\lambda$ value estimated from the sample of the previous iteration. Specifically, iteration $k$ uses the Gibbs sampler of Section 2 with hyperparameter $\\lambda^{(k-1)}$ (i.e., the estimate from iteration $k-1$) to approximate the ideal updated estimate:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(k)} = \\sqrt{\\frac{2p}{\\sum\\limits^p_{j=1}E_{\\lambda^{(k-1)}}[\\tau^2_j|\\tilde{y}]}}$ </h3>\n",
    "\n",
    "by replacing the conditional expectations with averages from the Gibbs sample. We suggest the initial value:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(0)} = \\frac{p\\sqrt{\\hat{\\sigma}^2_{LS}}}{\\sum\\limits^p_{j=1}|\\hat{\\beta}^{LS}_j|}$ </h3>\n",
    "\n",
    "where $\\hat{\\sigma}^2_{LS}$ and $\\hat{\\beta}^{LS}_j$ are estimates from the usual least squares procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lambda_init\n",
    "lambda_init = (X.shape[1]*np.sqrt((np.sum((Y - lm.predict(X))**2))/(X.shape[0]-X.shape[1])))/np.sum(np.abs(lm.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# This will be used to find the next k lambda\n",
    "for i in range(50):\n",
    "    if i==0:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_init), axis=0)))\n",
    "    else:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_), axis=0)))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23828477705791679"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Hyperpriors for the Lasso Parameter\n",
    "\n",
    "We need to modify the previous Gibbs sampler by introducing the full conditional distribution of $\\lambda^2$, which is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{G}amma(p+r, \\frac{\\sum\\limits_{j=1}^p\\tau^2_j}{2}+\\delta)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler_bis(n, r, delta):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    lambda_sq = [np.random.uniform()]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_sq[i]*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_sq[i], X.shape[1])\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "        # Full conditional for lambda_sq\n",
    "        shape = X.shape[1] + r\n",
    "        rate = sum(tau_sq[i+1])/2+delta\n",
    "        lambda_sq.append(np.random.gamma(shape, rate))\n",
    "    return lambda_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_sq_bis = Gibbs_sampler_bis(100, 1, 1.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62062817810426596,\n",
       " 16.157373770097731,\n",
       " 5.4679394269839383,\n",
       " 4.6901907931653808,\n",
       " 5.9815623561679434,\n",
       " 6.0032726704971004,\n",
       " 7.3349773707512362,\n",
       " 5.9764369899816199,\n",
       " 5.7204033158312786,\n",
       " 5.2999992693004812,\n",
       " 6.3926540857261029,\n",
       " 5.2718478726361901,\n",
       " 5.7601066453121863,\n",
       " 6.4975610349059627,\n",
       " 4.3161302478534447,\n",
       " 7.1059933549703924,\n",
       " 5.3413023322325781,\n",
       " 5.3164966535817166,\n",
       " 5.2041865342265403,\n",
       " 4.5205408645188045,\n",
       " 5.8711032104448533,\n",
       " 5.9786193301490691,\n",
       " 5.2453268891217322,\n",
       " 7.295675667999741,\n",
       " 4.090849351159318,\n",
       " 5.2372853503111658,\n",
       " 6.3915260509538845,\n",
       " 6.6300395221264274,\n",
       " 6.6110112554705349,\n",
       " 7.5782867749974638,\n",
       " 5.0147225234389214,\n",
       " 5.575158055009064,\n",
       " 6.3113603799692921,\n",
       " 6.7273973067649084,\n",
       " 5.5573052374052203,\n",
       " 4.7786952064296386,\n",
       " 5.603501250681405,\n",
       " 4.8152826031754019,\n",
       " 7.0857585810376973,\n",
       " 5.0926067255852479,\n",
       " 7.237634206677928,\n",
       " 4.3497960419842636,\n",
       " 6.5437604054940959,\n",
       " 5.5881298940489845,\n",
       " 5.8539812384697631,\n",
       " 4.9370015661326896,\n",
       " 5.1679562805266013,\n",
       " 5.3257714650785575,\n",
       " 3.8839094919410559,\n",
       " 5.4028405502005503,\n",
       " 4.7943101481002781,\n",
       " 5.922471417569092,\n",
       " 5.6395673524264902,\n",
       " 5.8750904370993569,\n",
       " 5.5393018812802577,\n",
       " 5.4014066808688108,\n",
       " 5.9722876092071893,\n",
       " 5.7250672271056287,\n",
       " 5.5947360707780902,\n",
       " 6.1270241917330885,\n",
       " 5.2457264551963458,\n",
       " 6.2120449137452116,\n",
       " 6.8158294884038462,\n",
       " 5.1225358901754809,\n",
       " 6.2108874569917214,\n",
       " 6.8326260869318727,\n",
       " 6.3399953955327284,\n",
       " 6.9301322045693583,\n",
       " 4.6470940862861729,\n",
       " 7.1023295745875448,\n",
       " 4.5430526769679913,\n",
       " 6.0310607267665928,\n",
       " 4.8839008026938462,\n",
       " 6.0976732835213374,\n",
       " 4.6575307564111252,\n",
       " 6.9380548799568391,\n",
       " 6.2739036607014409,\n",
       " 4.1953494606666792,\n",
       " 4.968095232404349,\n",
       " 7.0070488088438667,\n",
       " 5.2887303308697406,\n",
       " 5.8057300324467267,\n",
       " 5.2090719133435401,\n",
       " 6.6112233047500055,\n",
       " 5.5173298293560311,\n",
       " 5.7566545669298899,\n",
       " 5.6335712326780358,\n",
       " 6.1717618783580797,\n",
       " 6.3935633212225156,\n",
       " 5.513282887002493,\n",
       " 6.5087656322308058,\n",
       " 4.9819518922669417,\n",
       " 4.9430497983386559,\n",
       " 5.7242025743821676,\n",
       " 5.9322301250635183,\n",
       " 6.4719923478055872,\n",
       " 7.0229109881128586,\n",
       " 5.3093494591890193,\n",
       " 6.6136751091487138,\n",
       " 7.1031487695878317,\n",
       " 5.5540063387830942]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sqrt(i) for i in lambda_sq_bis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2] Test on largest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('digits_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
