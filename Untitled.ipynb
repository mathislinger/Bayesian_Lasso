{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.txt', sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the good data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define X and Y arrays\n",
    "X = data.iloc[:,:data.shape[1]-1].as_matrix()\n",
    "Y = data.iloc[:,data.shape[1]-1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We center the Y\n",
    "Y_tilde = Y - Y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "beta = np.random.uniform(size = X.shape[1])\n",
    "sigma_sq = np.random.uniform()\n",
    "tau_sq = np.random.uniform(size = X.shape[1])\n",
    "\n",
    "beta_ = []\n",
    "sigma_sq_ = []\n",
    "tau_sq_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D_tau = np.diag(tau_sq)\n",
    "A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "multi_norm_cov = sigma_sq * np.linalg.inv(A)\n",
    "beta_.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (X.shape[0]-1+X.shape[1])/2\n",
    "scale = ((Y_tilde - X.dot(beta)).dot((Y_tilde - X.dot(beta))) + beta.transpose().dot(np.linalg.inv(D_tau)).dot(beta))/2\n",
    "sigma_sq_.append(sc.invgamma.rvs(a = shape, scale = scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\tau^2_1, ..., \\tau^2_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Say lambda 0 is equal to 1\n",
    "lambda_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.sqrt(lambda_**2*sigma_sq/beta**2)\n",
    "scale = lambda_**2\n",
    "tau_sq_.append(np.random.wald(mean, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(tau_sq)):\n",
    "    t.append(np.random.wald(mean[i], scale))\n",
    "tau_sq_.append(np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler(n, lambda_):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_**2*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_**2, X.shape[1])\n",
    "        #scale = lambda_**2\n",
    "        #t = []\n",
    "        #for j in range(len(mean)):\n",
    "        #    t.append(np.random.wald(mean[j], scale))\n",
    "        #tau_sq.append(np.array(t))\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "    return tau_sq[int(n/2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo EM algorithm that complements the Gibbs sampler and provides marginal maximum likelihood estimates of hyperparameters\n",
    "\n",
    "For the Bayesian Lasso, each iteration of the algorithm involves running the Gibbs sampler using a $\\lambda$ value estimated from the sample of the previous iteration. Specifically, iteration $k$ uses the Gibbs sampler of Section 2 with hyperparameter $\\lambda^{(k-1)}$ (i.e., the estimate from iteration $k-1$) to approximate the ideal updated estimate:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(k)} = \\sqrt{\\frac{2p}{\\sum\\limits^p_{j=1}E_{\\lambda^{(k-1)}}[\\tau^2_j|\\tilde{y}]}}$ </h3>\n",
    "\n",
    "by replacing the conditional expectations with averages from the Gibbs sample. We suggest the initial value:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(0)} = \\frac{p\\sqrt{\\hat{\\sigma}^2_{LS}}}{\\sum\\limits^p_{j=1}|\\hat{\\beta}^{LS}_j|}$ </h3>\n",
    "\n",
    "where $\\hat{\\sigma}^2_{LS}$ and $\\hat{\\beta}^{LS}_j$ are estimates from the usual least squares procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lambda_init\n",
    "lambda_init = (X.shape[1]*np.sqrt((np.sum((Y - lm.predict(X))**2))/(X.shape[0]-X.shape[1])))/np.sum(np.abs(lm.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# This will be used to find the next k lambda\n",
    "for i in range(50):\n",
    "    if i==0:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_init), axis=0)))\n",
    "    else:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_), axis=0)))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23425384342633901"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
