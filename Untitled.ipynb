{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.txt', sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the good data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define X and Y arrays\n",
    "X = data.iloc[:,:data.shape[1]-1].as_matrix()\n",
    "Y = data.iloc[:,data.shape[1]-1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We center the Y\n",
    "Y_tilde = Y - Y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "beta = np.random.uniform(size = X.shape[1])\n",
    "sigma_sq = np.random.uniform()\n",
    "tau_sq = np.random.uniform(size = X.shape[1])\n",
    "\n",
    "beta_ = []\n",
    "sigma_sq_ = []\n",
    "tau_sq_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D_tau = np.diag(tau_sq)\n",
    "A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "multi_norm_cov = sigma_sq * np.linalg.inv(A)\n",
    "beta_.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (X.shape[0]-1+X.shape[1])/2\n",
    "scale = ((Y_tilde - X.dot(beta)).dot((Y_tilde - X.dot(beta))) + beta.transpose().dot(np.linalg.inv(D_tau)).dot(beta))/2\n",
    "sigma_sq_.append(sc.invgamma.rvs(a = shape, scale = scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full conditional for $\\tau^2_1, ..., \\tau^2_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Say lambda 0 is equal to 1\n",
    "lambda_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.sqrt(lambda_**2*sigma_sq/beta**2)\n",
    "scale = lambda_**2\n",
    "tau_sq_.append(np.random.wald(mean, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(tau_sq)):\n",
    "    t.append(np.random.wald(mean[i], scale))\n",
    "tau_sq_.append(np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "The Gibbs sampler used here uses the following full conditional distributions:\n",
    "\n",
    "- The full conditional for $\\beta$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{N}_p(A^{-1}X^T\\tilde{y}, \\sigma^2A^{-1})$ where $A = X^TX+D^{-1}_\\tau$ and $D_\\tau = diag(\\tau^2_1,...,\\tau^2_p)$ </h3>\n",
    "\n",
    "- The full conditional for $\\sigma^2$ is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}amma(\\frac{n-1+p}{2}, \\frac{(\\tilde{y}-X\\beta)^T(\\tilde{y}-X\\beta) + \\beta^TD^{-1}_\\tau\\beta}{2})$ </h3>\n",
    "\n",
    "- $\\tau^2_1, ..., \\tau^2_p$ are conditionnaly independent and $\\frac{1}{\\tau^2_j}$ has as conditional distribution:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{I}nverse\\mathcal{G}ausian(\\sqrt{\\frac{\\lambda^2\\sigma^2}{\\beta^2_j}}, \\lambda^2)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler(n, lambda_):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_**2*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_**2, X.shape[1])\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "    return tau_sq[int(n/2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Bayes by Marginal Maximum Likelihood\n",
    "\n",
    "For the Bayesian Lasso, each iteration of the algorithm involves running the Gibbs sampler using a $\\lambda$ value estimated from the sample of the previous iteration. Specifically, iteration $k$ uses the Gibbs sampler of Section 2 with hyperparameter $\\lambda^{(k-1)}$ (i.e., the estimate from iteration $k-1$) to approximate the ideal updated estimate:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(k)} = \\sqrt{\\frac{2p}{\\sum\\limits^p_{j=1}E_{\\lambda^{(k-1)}}[\\tau^2_j|\\tilde{y}]}}$ </h3>\n",
    "\n",
    "by replacing the conditional expectations with averages from the Gibbs sample. We suggest the initial value:\n",
    "\n",
    "<h3 align=\"center\"> $\\lambda^{(0)} = \\frac{p\\sqrt{\\hat{\\sigma}^2_{LS}}}{\\sum\\limits^p_{j=1}|\\hat{\\beta}^{LS}_j|}$ </h3>\n",
    "\n",
    "where $\\hat{\\sigma}^2_{LS}$ and $\\hat{\\beta}^{LS}_j$ are estimates from the usual least squares procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X,Y_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lambda_init\n",
    "lambda_init = (X.shape[1]*np.sqrt((np.sum((Y_tilde - lm.predict(X))**2))/(X.shape[0]-X.shape[1])))/np.sum(np.abs(lm.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# This will be used to find the next k lambda\n",
    "for i in range(50):\n",
    "    if i==0:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_init), axis=0)))\n",
    "    else:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler(1000, lambda_), axis=0)))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23821022738257597"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Hyperpriors for the Lasso Parameter\n",
    "\n",
    "We need to modify the previous Gibbs sampler by introducing the full conditional distribution of $\\lambda^2$, which is:\n",
    "\n",
    "<h3 align=\"center\"> $\\mathcal{G}amma(p+r, \\frac{\\sum\\limits_{j=1}^p\\tau^2_j}{2}+\\delta)$ </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler_bis(n, r, delta):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    lambda_sq = [np.random.uniform()]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_sq[i]*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_sq[i], X.shape[1])\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "        # Full conditional for lambda_sq\n",
    "        shape = X.shape[1] + r\n",
    "        rate = sum(tau_sq[i+1])/2+delta\n",
    "        lambda_sq.append(np.random.gamma(shape, rate))\n",
    "    return lambda_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_sq_bis = Gibbs_sampler_bis(100, 1, 1.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84877592778732369,\n",
       " 12.951218973183863,\n",
       " 4.8133913562195758,\n",
       " 7.3215760493712594,\n",
       " 4.993177218613094,\n",
       " 6.6594979998852093,\n",
       " 5.7323766813285619,\n",
       " 5.8944124885727947,\n",
       " 4.1975661490796776,\n",
       " 4.6253644011603336,\n",
       " 6.7416507550183544,\n",
       " 6.7442151095468361,\n",
       " 5.2919586527793481,\n",
       " 4.5136676138996528,\n",
       " 7.6497913394336852,\n",
       " 6.3083527341907946,\n",
       " 5.9436009321764489,\n",
       " 6.7282414240871686,\n",
       " 5.8838125131736385,\n",
       " 6.2096421031898981,\n",
       " 5.3091594823880905,\n",
       " 4.9445297813571347,\n",
       " 5.4278767328783903,\n",
       " 8.3936268517138224,\n",
       " 5.6499735723890465,\n",
       " 5.2949740082684587,\n",
       " 6.5621096221838302,\n",
       " 5.489062426367477,\n",
       " 5.921253049180236,\n",
       " 4.7059345629519198,\n",
       " 6.2153537864026882,\n",
       " 5.4549506894682915,\n",
       " 6.066635027902433,\n",
       " 5.715750554961498,\n",
       " 5.6208251325083269,\n",
       " 4.9679023503898598,\n",
       " 5.4330730408529444,\n",
       " 5.8598376952009463,\n",
       " 6.4776180929443195,\n",
       " 6.108033259480532,\n",
       " 3.9404301715265384,\n",
       " 6.9230723841480026,\n",
       " 3.9046332337821728,\n",
       " 7.531842047803484,\n",
       " 6.8390099000762747,\n",
       " 4.3383468731145776,\n",
       " 7.5913685607750159,\n",
       " 5.1682127959117699,\n",
       " 6.3601884158395148,\n",
       " 6.6519085412540147,\n",
       " 4.2751290301720131,\n",
       " 7.949863742306448,\n",
       " 6.061305235406893,\n",
       " 5.5204035916550129,\n",
       " 4.1981702541777794,\n",
       " 7.1112561463851272,\n",
       " 5.5277014128999564,\n",
       " 4.4095346504573119,\n",
       " 5.9764085930476218,\n",
       " 5.010002360457702,\n",
       " 5.7915876587209016,\n",
       " 5.8374953120048572,\n",
       " 5.664094242401899,\n",
       " 6.5123815869224817,\n",
       " 5.543099562814553,\n",
       " 5.1883553765377073,\n",
       " 6.8389303189414727,\n",
       " 3.5845166495952414,\n",
       " 6.3596017094192687,\n",
       " 3.456252514731919,\n",
       " 6.6960146734215353,\n",
       " 5.3865882115843506,\n",
       " 3.8768151095117287,\n",
       " 4.588209589998316,\n",
       " 6.4634650547326151,\n",
       " 6.2138358184318925,\n",
       " 6.3045220982741235,\n",
       " 5.8821011276480197,\n",
       " 6.5769156044307877,\n",
       " 5.5956768702585453,\n",
       " 6.0655110206433624,\n",
       " 5.1319608481706167,\n",
       " 6.305828304852322,\n",
       " 4.9900229403741516,\n",
       " 6.8020507851790146,\n",
       " 6.3838228427641779,\n",
       " 4.6287902578059672,\n",
       " 9.0282078229670297,\n",
       " 5.7266719691361949,\n",
       " 6.537597161750913,\n",
       " 5.2917136627555879,\n",
       " 7.0273275658982488,\n",
       " 7.8508205171137462,\n",
       " 6.4928472773098589,\n",
       " 5.2110140496348683,\n",
       " 5.5849347258426274,\n",
       " 4.9196972346274368,\n",
       " 5.2968688404082984,\n",
       " 6.3604716662837228,\n",
       " 6.5210374823460384,\n",
       " 5.1368948678802351]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sqrt(i) for i in lambda_sq_bis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2] Test on largest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('digits_train.csv')\n",
    "train = train.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:,1:].as_matrix()\n",
    "Y_tilde = train.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X,Y_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lambda_init\n",
    "lambda_init = (X.shape[1]*np.sqrt((np.sum((Y_tilde - lm.predict(X))**2))/(X.shape[0]-X.shape[1])))/np.sum(np.abs(lm.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# This will be used to find the next k lambda\n",
    "for i in range(20):\n",
    "    if i==0:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler_corrected(5, lambda_init), axis=0)))\n",
    "    else:\n",
    "        lambda_ = np.sqrt(2*X.shape[1]/sum(np.mean(Gibbs_sampler_corrected(5, lambda_), axis=0)))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem encountered in large dimansion with sparse dataset: Theory vs Implementation\n",
    "\n",
    "We have the problem that $\\sigma^2A^{-1}$ which is the covariance matrix used to generate the $\\beta$'s is from the computer point of view not positive semi-definite.\n",
    "\n",
    "Theoretically, the matrix is positive semidefinite, with several eigenvalues being exactly zero. But the computations with floating point numbers introduce truncation errors which result in some of those eigenvalues being very small but negative; hence, the matrix is not positive semidefinite.\n",
    "\n",
    "A way to correct for the floating point errors is to add a tiny multiple of the identity matrix to the covariance matrix. I take this into account and add it in my Gibbs sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampler_corrected(n, lambda_):\n",
    "    # Initialization\n",
    "    beta = [np.random.uniform(size = X.shape[1])]\n",
    "    sigma_sq = [np.random.uniform()]\n",
    "    tau_sq = [np.random.uniform(size = X.shape[1])]\n",
    "    for i in range(n):\n",
    "        # Full conditional for beta\n",
    "        D_tau = np.diag(tau_sq[i])\n",
    "        A = X.transpose().dot(X) + np.linalg.inv(D_tau)\n",
    "        multi_norm_mean = np.linalg.inv(A).dot(X.transpose()).dot(Y_tilde)\n",
    "        min_eig = np.min(np.real(np.linalg.inv(A)))\n",
    "        if min_eig < 0:\n",
    "            A -= 10*min_eig * np.eye(*A.shape)\n",
    "        multi_norm_cov = sigma_sq[i] * np.linalg.inv(A)\n",
    "        beta.append(np.random.multivariate_normal(multi_norm_mean, multi_norm_cov))\n",
    "        # Full conditional for sigma_sq\n",
    "        shape = (X.shape[0]-1+X.shape[1])/2\n",
    "        scale = ((Y_tilde - X.dot(beta[i+1])).dot((Y_tilde - X.dot(beta[i+1]))) + beta[i+1].transpose().dot(np.linalg.inv(D_tau)).dot(beta[i+1]))/2\n",
    "        sigma_sq.append(sc.invgamma.rvs(a = shape, scale = scale))\n",
    "        # Full conditional for tau_1,...,tau_p\n",
    "        mean = np.sqrt(lambda_**2*sigma_sq[i+1]/beta[i+1]**2)\n",
    "        scale = np.repeat(lambda_**2, X.shape[1])\n",
    "        tau_sq.append(1/np.random.wald(mean, scale))\n",
    "    return tau_sq[int(n/2):]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
